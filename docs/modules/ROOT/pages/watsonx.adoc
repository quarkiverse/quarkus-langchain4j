= IBM watsonx.ai

include::./includes/attributes.adoc[]

You can develop generative AI solutions with foundation models in IBM watsonx.ai. You can use prompts to generate, classify, summarize, or extract content from your input text. Choose from IBM models or open source models from Hugging Face. You can tune foundation models to customize your prompt output or optimize inferencing performance.

IMPORTANT: Supported only for IBM watsonx as a service on link:https://www.ibm.com/products/watsonx-ai/foundation-models[IBM Cloud].

== Using watsonx.ai

To employ watsonx.ai LLMs, integrate the following dependency into your project:

[source,xml,subs=attributes+]
----
<dependency>
    <groupId>io.quarkiverse.langchain4j</groupId>
    <artifactId>quarkus-langchain4j-watsonx</artifactId>
    <version>{project-version}</version>
</dependency>
----

If no other extension is installed, xref:ai-services.adoc[AI Services] will automatically utilize the configured watsonx dependency.

=== Configuration
To use the watsonx.ai dependency, you must configure some required values in the `application.properties` file.

---

==== Base URL
The `base-url` property depends on the region of the provided service instance, use one of the following values:

* Dallas: https://us-south.ml.cloud.ibm.com
* Frankfurt: https://eu-de.ml.cloud.ibm.com
* London: https://eu-gb.ml.cloud.ibm.com
* Tokyo: https://jp-tok.ml.cloud.ibm.com
* Sydney: https://au-syd.ml.cloud.ibm.com
* Toronto: https://ca-tor.ml.cloud.ibm.com

[source,properties,subs=attributes+]
----
quarkus.langchain4j.watsonx.base-url=https://us-south.ml.cloud.ibm.com
----

---

==== Project ID
To prompt foundation models in watsonx.ai, you need to pass the identifier of a project.

To get the ID of a project, complete the following steps:

1. Go to https://dataplatform.cloud.ibm.com/projects/?context=wx.
2. Open the project, and then click the Manage tab.
3. Copy the project ID from the Details section of the General page.

[source,properties,subs=attributes+]
----
quarkus.langchain4j.watsonx.project-id=23d...
----

NOTE: If you like, you can use the Space ID property with `quarkus.langchain4j.watsonx.space-id`

---

==== API Key
To use foundation models in IBM Watsonx.ai, you need an IBM Cloud API key. 

Follow these steps to generate one:

1. Go to https://cloud.ibm.com/iam/apikeys.
2. Click `Create +` button.
3. Provide a name and description for your new API key, then click `Create`.
4. Copy or securely save the API key.

[source,properties,subs=attributes+]
----
quarkus.langchain4j.watsonx.api-key=hG-...
----

---

=== Modes of Interaction

The `watsonx.ai` module provides two modes for interacting with large language models: `chat` and `generation`. These modes allow you to tailor interactions based on the complexity of your use case and the level of control you require over the prompt structure.

You can select the interaction mode using the property `quarkus.langchain4j.watsonx.mode`.

* **`chat`**: This mode abstracts the complexity of tagging by automatically formatting prompts (*default value*). 
* **`generation`**: In this mode, you must explicitly structure the prompts using the required model-specific tags. This provides full control over the format of the prompt but requires in-depth knowledge of the model being used. For best results, always refer to the documentation provided for each model to maximize the effectiveness of your prompts.

Each mode uses its own property namespace for customization:

* For `chat` mode the properties are under `quarkus.langchain4j.watsonx.chat-model`.
* For `generation` mode properties are under `quarkus.langchain4j.watsonx.generation-model`.

---

==== Chat Mode Example
The following example demonstrates how to configure and use `chat` mode:

[source,properties,subs=attributes+]
----
quarkus.langchain4j.watsonx.base-url=${BASE_URL}
quarkus.langchain4j.watsonx.api-key=${API_KEY}
quarkus.langchain4j.watsonx.project-id=${PROJECT_ID}
quarkus.langchain4j.watsonx.chat-model.model-id=mistralai/mistral-large
quarkus.langchain4j.watsonx.mode=chat // You can omit this property, as 'chat' is the default mode.
----

[source,java]
----
@RegisterAiService
public interface AiService {
    @SystemMessage("You are a helpful assistant")
    public String chat(@MemoryId String id, @UserMessage message);
}
----

---

==== Generation Mode Example
The following example demonstrates how to configure and use `generation` mode:

[source,properties,subs=attributes+]
----
quarkus.langchain4j.watsonx.base-url=${BASE_URL}
quarkus.langchain4j.watsonx.api-key=${API_KEY}
quarkus.langchain4j.watsonx.project-id=${PROJECT_ID}
quarkus.langchain4j.watsonx.generation-model.model-id=mistralai/mistral-large
quarkus.langchain4j.watsonx.mode=generation
----

[source,java]
----
@RegisterAiService(chatMemoryProviderSupplier = RegisterAiService.NoChatMemoryProviderSupplier.class)
public interface AiService {
    @SystemMessage("<s>[INST] You are a helpful assistant [/INST]</s>")
    @UserMessage("[INST] What is the capital of {capital}? [/INST]")
    public String askCapital(String capital);
}
----

NOTE: The `@SystemMessage` and `@UserMessage` annotations are joined by default with no separator (an empty string `""`). If you want to change this behavior, use the property `quarkus.langchain4j.watsonx.generation-model.prompt-joiner=<value>`.

==== All configuration properties

include::includes/quarkus-langchain4j-watsonx.adoc[leveloffset=+1,opts=optional]