[.configuration-legend]
icon:lock[title=Fixed at build time] Configuration property fixed at build time - All other configuration properties are overridable at runtime
[.configuration-reference.searchable, cols="80,.^10,.^10"]
|===

h|[.header-title]##Configuration property##
h|Type
h|Default

a|icon:lock[title=Fixed at build time] [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-include-models-in-artifact]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-include-models-in-artifact[`quarkus.langchain4j.gpu-llama3.include-models-in-artifact`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.include-models-in-artifact+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Determines whether the necessary GPULlama3 models are downloaded and included in the jar at build time. Currently, this option is only valid for `fast-jar` deployments.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_INCLUDE_MODELS_IN_ARTIFACT+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_INCLUDE_MODELS_IN_ARTIFACT+++`
endif::add-copy-button-to-env-var[]
--
|boolean
|`true`

a|icon:lock[title=Fixed at build time] [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-enabled]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-enabled[`quarkus.langchain4j.gpu-llama3.chat-model.enabled`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.chat-model.enabled+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Whether the model should be enabled


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_ENABLED+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_ENABLED+++`
endif::add-copy-button-to-env-var[]
--
|boolean
|`true`

a|icon:lock[title=Fixed at build time] [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-model-name]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-model-name[`quarkus.langchain4j.gpu-llama3.chat-model.model-name`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.chat-model.model-name+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Model name to use


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_MODEL_NAME+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_MODEL_NAME+++`
endif::add-copy-button-to-env-var[]
--
|string
|`beehive-lab/Llama-3.2-1B-Instruct-GGUF`

a|icon:lock[title=Fixed at build time] [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-quantization]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-quantization[`quarkus.langchain4j.gpu-llama3.chat-model.quantization`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.chat-model.quantization+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Quantization of the model to use


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_QUANTIZATION+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_QUANTIZATION+++`
endif::add-copy-button-to-env-var[]
--
|string
|`FP16`

a|icon:lock[title=Fixed at build time] [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-models-path]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-models-path[`quarkus.langchain4j.gpu-llama3.models-path`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.models-path+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Location on the file-system which serves as a cache for the models


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_MODELS_PATH+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_MODELS_PATH+++`
endif::add-copy-button-to-env-var[]
--
|path
|`${user.home}/.langchain4j/models`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-temperature]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-temperature[`quarkus.langchain4j.gpu-llama3.chat-model.temperature`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.chat-model.temperature+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
What sampling temperature to use, between 0.0 and 1.0.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_TEMPERATURE+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_TEMPERATURE+++`
endif::add-copy-button-to-env-var[]
--
|double
|`0.3`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-top-p]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-top-p[`quarkus.langchain4j.gpu-llama3.chat-model.top-p`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.chat-model.top-p+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
What sampling topP to use, between 0.0 and 1.0.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_TOP_P+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_TOP_P+++`
endif::add-copy-button-to-env-var[]
--
|double
|`0.85`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-seed]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-seed[`quarkus.langchain4j.gpu-llama3.chat-model.seed`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.chat-model.seed+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
What seed value to use.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_SEED+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_SEED+++`
endif::add-copy-button-to-env-var[]
--
|int
|`1234`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-max-tokens]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-chat-model-max-tokens[`quarkus.langchain4j.gpu-llama3.chat-model.max-tokens`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.chat-model.max-tokens+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
The maximum number of tokens to generate in the completion.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_MAX_TOKENS+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_CHAT_MODEL_MAX_TOKENS+++`
endif::add-copy-button-to-env-var[]
--
|int
|`512`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-enable-integration]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-enable-integration[`quarkus.langchain4j.gpu-llama3.enable-integration`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.enable-integration+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Whether to enable the integration. Set to `false` to disable all requests.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_ENABLE_INTEGRATION+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_ENABLE_INTEGRATION+++`
endif::add-copy-button-to-env-var[]
--
|boolean
|`true`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-log-requests]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-log-requests[`quarkus.langchain4j.gpu-llama3.log-requests`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.log-requests+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Whether GPULlama3 should log requests


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_LOG_REQUESTS+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_LOG_REQUESTS+++`
endif::add-copy-button-to-env-var[]
--
|boolean
|`false`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-log-responses]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-log-responses[`quarkus.langchain4j.gpu-llama3.log-responses`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3.log-responses+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Whether GPULlama3 client should log responses


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_LOG_RESPONSES+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3_LOG_RESPONSES+++`
endif::add-copy-button-to-env-var[]
--
|boolean
|`false`

h|[[quarkus-langchain4j-gpu-llama3_section_quarkus-langchain4j-gpu-llama3]] [.section-name.section-level0]##link:#quarkus-langchain4j-gpu-llama3_section_quarkus-langchain4j-gpu-llama3[Named model config]##
h|Type
h|Default

a|icon:lock[title=Fixed at build time] [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-model-name]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-model-name[`quarkus.langchain4j.gpu-llama3."model-name".chat-model.model-name`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".chat-model.model-name+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Model name to use


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_MODEL_NAME+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_MODEL_NAME+++`
endif::add-copy-button-to-env-var[]
--
|string
|`beehive-lab/Llama-3.2-1B-Instruct-GGUF`

a|icon:lock[title=Fixed at build time] [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-quantization]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-quantization[`quarkus.langchain4j.gpu-llama3."model-name".chat-model.quantization`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".chat-model.quantization+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Quantization of the model to use


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_QUANTIZATION+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_QUANTIZATION+++`
endif::add-copy-button-to-env-var[]
--
|string
|`FP16`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-temperature]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-temperature[`quarkus.langchain4j.gpu-llama3."model-name".chat-model.temperature`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".chat-model.temperature+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
What sampling temperature to use, between 0.0 and 1.0.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_TEMPERATURE+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_TEMPERATURE+++`
endif::add-copy-button-to-env-var[]
--
|double
|`0.3`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-top-p]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-top-p[`quarkus.langchain4j.gpu-llama3."model-name".chat-model.top-p`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".chat-model.top-p+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
What sampling topP to use, between 0.0 and 1.0.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_TOP_P+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_TOP_P+++`
endif::add-copy-button-to-env-var[]
--
|double
|`0.85`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-seed]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-seed[`quarkus.langchain4j.gpu-llama3."model-name".chat-model.seed`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".chat-model.seed+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
What seed value to use.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_SEED+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_SEED+++`
endif::add-copy-button-to-env-var[]
--
|int
|`1234`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-max-tokens]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-chat-model-max-tokens[`quarkus.langchain4j.gpu-llama3."model-name".chat-model.max-tokens`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".chat-model.max-tokens+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
The maximum number of tokens to generate in the completion.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_MAX_TOKENS+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__CHAT_MODEL_MAX_TOKENS+++`
endif::add-copy-button-to-env-var[]
--
|int
|`512`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-enable-integration]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-enable-integration[`quarkus.langchain4j.gpu-llama3."model-name".enable-integration`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".enable-integration+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Whether to enable the integration. Set to `false` to disable all requests.


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__ENABLE_INTEGRATION+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__ENABLE_INTEGRATION+++`
endif::add-copy-button-to-env-var[]
--
|boolean
|`true`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-log-requests]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-log-requests[`quarkus.langchain4j.gpu-llama3."model-name".log-requests`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".log-requests+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Whether GPULlama3 should log requests


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__LOG_REQUESTS+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__LOG_REQUESTS+++`
endif::add-copy-button-to-env-var[]
--
|boolean
|`false`

a| [[quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-log-responses]] [.property-path]##link:#quarkus-langchain4j-gpu-llama3_quarkus-langchain4j-gpu-llama3-model-name-log-responses[`quarkus.langchain4j.gpu-llama3."model-name".log-responses`]##
ifdef::add-copy-button-to-config-props[]
config_property_copy_button:+++quarkus.langchain4j.gpu-llama3."model-name".log-responses+++[]
endif::add-copy-button-to-config-props[]


[.description]
--
Whether GPULlama3 client should log responses


ifdef::add-copy-button-to-env-var[]
Environment variable: env_var_with_copy_button:+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__LOG_RESPONSES+++[]
endif::add-copy-button-to-env-var[]
ifndef::add-copy-button-to-env-var[]
Environment variable: `+++QUARKUS_LANGCHAIN4J_GPU_LLAMA3__MODEL_NAME__LOG_RESPONSES+++`
endif::add-copy-button-to-env-var[]
--
|boolean
|`false`


|===

