= Quarkus Langchain4j

include::./includes/attributes.adoc[]

_Large Language Models_ (LLMs) are AI-based systems designed to understand, generate, and manipulate human language, showcasing advanced natural language processing capabilities.
The dynamic LLM landscape is reshaping our interactions with applications and the very construction of these applications.
The Quarkus LangChain4j extension seamlessly integrates LLMs into Quarkus applications, enabling the harnessing of LLM capabilities for the development of more intelligent applications.

For instance, an application utilizing this extension can:

- Automatically triage or classify documents
- Extract structured and unstructured information from various data sources
- Construct chatbots for system interaction
- Generate personalized text such as emails or reports

This extension is built upon the https://github.com/langchain4j/langchain4j[LangChain4j library].
It offers a declarative approach to interact with diverse LLMs like OpenAI, Hugging Face, or Ollama. It facilitates LLM-invoked functions within Quarkus applications and allows document loading within the LLM "context".

image::llms-big-picture.png[width=600,align="center"]

== Quick Overview

To incorporate Quarkus Langchain4j into your Quarkus project, add the following Maven dependency:

[source,xml,subs=attributes+]
----
<dependency>
    <groupId>io.quarkiverse.langchain4j</groupId>
    <artifactId>quarkus-langchain4j-openai</artifactId>
    <version>{project-version}</version>
</dependency>
----

or, to use hugging face:

[source,xml,subs=attributes+]
----
<dependency>
    <groupId>io.quarkiverse.langchain4j</groupId>
    <artifactId>quarkus-langchain4j-huggingface</artifactId>
    <version>{project-version}</version>
</dependency>
----


Then, include your OpenAI API key in your `application.properties` file (or any other mandatory configuration):

[source,properties,subs=attributes+]
----
quarkus.langchain4j.openai.api-key=sk-...
----

TIP: Alternatively, utilize the `QUARKUS_LANGCHAIN4J_OPENAI_API_KEY` environment variable.

Once you've added the dependency and configuration, the next step involves creating an _AI service_, serving as the integration point. This service is the interface your application code will utilize to interact with the LLM. A basic example is demonstrated below:

[source,java]
----
include::{examples-dir}/io/quarkiverse/langchain4j/samples/MyAiService.java[]
----
<1> The `@RegisterAiService` annotation registers the _AI service_.
<2> The `tools` attribute defines the _tools_ the LLM can employ.
During interaction, the LLM can invoke these tools and reflect on their output.
<3> The `@SystemMessage` annotation registers a _system message_, setting the initial context or "scope".
<4> The `@UserMessage` annotation serves as the _prompt_.
<5> The method invokes the LLM, initiating an exchange between the LLM and the application, beginning with the system message and then the user message. Your application triggers this method and receives the response.

== Advantages over vanilla Langchain4j

The extension offers the following advantages over using the vanilla https://github.com/langchain4j/langchain4j[LangChain4j] library in Quarkus:

* Seamless integration with the Quarkus programming model
** CDI beans for the Langchain4j models
** Standard configuration properties for configuring said models
* xref:ai-services.adoc[Declarative AI Services]
* Built-in observability
** Metrics
** Tracing
** Auditing
* Build time wiring
** Reduced footprint of the library
** Feedback about misuse at build time
* Leverage runtime Quarkus components
** REST calls and JSON handling are performed using the libraries used throughout Quarkus
*** Results in reduces library footprint
*** Enables GraalVM native image compilation
* Dev UI features
** View table with information about AI services and tools
** Add embeddings into the embedding store
** Search for relevant embeddings in the embedding store

