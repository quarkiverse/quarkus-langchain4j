quarkus.langchain4j.timeout=60s
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true
quarkus.langchain4j.ollama.chat-model.model-id = llama3
quarkus.langchain4j.ollama.chat-model.temperature = 0.0
quarkus.langchain4j.ollama.chat-model.num-ctx = 3072
quarkus.langchain4j.ollama.chat-model.num-predict = 3072
quarkus.langchain4j.ollama.experimental-tools = PARALLEL

quarkus.log.category."io.quarkiverse.langchain4j.runtime.aiservice".level=DEBUG
