quarkus.langchain4j.ollama.log-requests = true
quarkus.langchain4j.ollama.log-responses = true
quarkus.langchain4j.ollama.chat-model.num-predict = 8192
quarkus.langchain4j.ollama.chat-model.num-ctx = 4096

quarkus.log.category."io.quarkiverse.langchain4j.runtime.aiservice".level=DEBUG

# Not working llm: calebfahlgren/natural-functions , phi3, aya, mistral, gemma,
# Working llm: llama3, qwen2
quarkus.langchain4j.ollama.llama3.chat-model.model-id = llama3
quarkus.langchain4j.ollama.llama3.timeout = 60s
quarkus.langchain4j.ollama.llama3.chat-model.temperature = 0.0
quarkus.langchain4j.ollama.llama3.chat-model.num-ctx = 8192
quarkus.langchain4j.ollama.llama3.chat-model.num-predict = 8192
quarkus.langchain4j.ollama.llama3.experimental-tools = true

quarkus.langchain4j.ollama.mistral.chat-model.model-id = mistral
quarkus.langchain4j.ollama.mistral.timeout = 60s
quarkus.langchain4j.ollama.mistral.chat-model.temperature = 0.0
quarkus.langchain4j.ollama.mistral.experimental-tools = true

quarkus.langchain4j.ollama.qwen2.chat-model.model-id = qwen2
quarkus.langchain4j.ollama.qwen2.timeout = 60s
quarkus.langchain4j.ollama.qwen2.chat-model.temperature = 0.0
quarkus.langchain4j.ollama.qwen2.experimental-tools = true