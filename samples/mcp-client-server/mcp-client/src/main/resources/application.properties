quarkus.langchain4j.log-requests=true
quarkus.langchain4j.chat-model.provider=openai
%ollama.quarkus.langchain4j.chat-model.provider=ollama
%ollama.quarkus.langchain4j.ollama.chat-model.model-id=mistral

quarkus.langchain4j.mcp.weather.transport-type=streamable-http
quarkus.langchain4j.mcp.weather.url=http://localhost:8081/mcp/

quarkus.http.port=8080

quarkus.langchain4j.timeout=30s
%ollama.quarkus.langchain4j.timeout=1000s
%ollama.quarkus.vertx.max-worker-execute-time=${%ollama.quarkus.langchain4j.timeout}

#quarkus.log.category."io.quarkiverse.langchain4j.runtime.aiservice.AiServiceMethodImplementationSupport".level=DEBUG
